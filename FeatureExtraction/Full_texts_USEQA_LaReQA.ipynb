{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = pd.read_csv('./titles_speller.tsv', sep='\\t', header=None)\n",
    "# titles.columns=['Id', 'Title']\n",
    "\n",
    "titles = pd.read_csv('./titles_speller_stemmer.tsv', sep='\\t', header=None)\n",
    "titles.columns=['Id', 'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles['Title'] = titles['Title'].astype('str').apply(lambda x: x.strip())\n",
    "titles['Id'] = titles['Id'].apply(lambda x: int(x))\n",
    "titles = titles.sort_values(by=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_speller = pd.DataFrame(columns=['Id', 'Text'])\n",
    "df_speller_stemmer = pd.DataFrame(columns=['Id', 'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_speller = []\n",
    "lst_speller_stemmer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582168/582168 [03:54<00:00, 2485.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm.tqdm(os.listdir('./DOCS_TEXTS/')):\n",
    "    if '.ipynb' in doc:\n",
    "        continue\n",
    "    doc_id = doc.split('.')[0]\n",
    "    with open(os.path.join('./DOCS_TEXTS', doc), 'r') as f:\n",
    "        text_speller = f.readline()\n",
    "        title_speller_stemmer = f.readline()\n",
    "        \n",
    "        #lst_speller.append((doc_id, text_speller))\n",
    "        lst_speller_stemmer.append([doc_id, title_speller_stemmer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_speller = pd.DataFrame(lst_speller, columns =['Id', 'Text'])\n",
    "# df_speller['Id'] = df_speller['Id'].apply(lambda x: int(x))\n",
    "# df_speller = df_speller.sort_values(by=['Id'])\n",
    "\n",
    "df_speller_stemmer = pd.DataFrame(lst_speller_stemmer, columns =['Id', 'Text'])\n",
    "df_speller_stemmer['Id'] = df_speller_stemmer['Id'].apply(lambda x: int(x))\n",
    "df_speller_stemmer = df_speller_stemmer.sort_values(by=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = titles.merge(df_speller, left_on=['Id'], right_on=['Id']).sort_values(by=['Id'])\n",
    "merged = titles.merge(df_speller_stemmer, left_on=['Id'], right_on=['Id']).sort_values(by=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries = pd.read_csv('./query_speller.tsv', sep='\\t', header=None)\n",
    "# queries.columns = ['Id', 'Query']\n",
    "queries = pd.read_csv('./query_speller_stemmer.tsv', sep='\\t', header=None)\n",
    "queries.columns = ['Id', 'Query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13 причина почему</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1 положительный и 1 отрицательный мочь ли</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016 действовать ли зао рождественский мануфак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1 месяц после операция на кишечник диета что м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2 правда 1 ложь что можно придумывать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>6306</td>\n",
       "      <td>являться ли тойота харриер внедорожник</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>6307</td>\n",
       "      <td>як можно очищать креходить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>6308</td>\n",
       "      <td>являться ли реактив медицинский изделие</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>6309</td>\n",
       "      <td>являться ли словообразовательный пары слово го...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6310</th>\n",
       "      <td>6310</td>\n",
       "      <td>являться ли ооо субъект малый предпринимательство</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6311 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Query\n",
       "0        0                                  13 причина почему\n",
       "1        1          1 положительный и 1 отрицательный мочь ли\n",
       "2        2  2016 действовать ли зао рождественский мануфак...\n",
       "3        3  1 месяц после операция на кишечник диета что м...\n",
       "4        4              2 правда 1 ложь что можно придумывать\n",
       "...    ...                                                ...\n",
       "6306  6306             являться ли тойота харриер внедорожник\n",
       "6307  6307                         як можно очищать креходить\n",
       "6308  6308            являться ли реактив медицинский изделие\n",
       "6309  6309  являться ли словообразовательный пары слово го...\n",
       "6310  6310  являться ли ооо субъект малый предпринимательство\n",
       "\n",
       "[6311 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries['Id'] = queries['Id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('./Data/sample.csv', sep=',')\n",
    "sample_df.columns = ['query_id', 'url_id']\n",
    "\n",
    "marks_df = pd.read_csv('./Data/train.marks.tsv', sep='\\t', header=None)\n",
    "marks_df.columns = ['query_id', 'url_id', 'mark']\n",
    "marks_df = marks_df.drop(columns=['mark'])\n",
    "\n",
    "sample_df = sample_df.append(marks_df)\n",
    "\n",
    "sample_df['USE_QA'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = merged['Title']\n",
    "corpus = merged['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_q = list(sorted(set(sample_df['query_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1313/1313 [08:56<00:00,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for query in tqdm.tqdm(all_q):        \n",
    "    docs_id = list(sample_df[sample_df['query_id'] == query]['url_id'])\n",
    "    q = queries[queries['Id'] == query]['Query'][query]\n",
    "    try:\n",
    "        question_embeddings = module.signatures['question_encoder'](tf.constant(q))\n",
    "        responses = titles[docs_id]\n",
    "        response_contexts = corpus[docs_id]\n",
    "        response_embeddings = module.signatures['response_encoder'](\n",
    "            input=tf.constant(responses),\n",
    "            context=tf.constant(response_contexts))\n",
    "\n",
    "        sim = np.inner(question_embeddings['outputs'], response_embeddings['outputs']).ravel()\n",
    "        sample_df.loc[sample_df['query_id'] == query, 'USE_QA'] = sim\n",
    "        #sample_df.to_csv('USEQA_Full_Spelled.tsv',sep='\\t',index=False)\n",
    "    except:\n",
    "        question_embeddings = module.signatures['question_encoder'](tf.constant(q))\n",
    "        sim = []\n",
    "        for batch in np.array_split(docs_id, 50):   \n",
    "            responses = titles[batch]\n",
    "            response_contexts = corpus[batch]\n",
    "            response_embeddings = module.signatures['response_encoder'](\n",
    "                input=tf.constant(responses),\n",
    "                context=tf.constant(response_contexts))\n",
    "            sim.extend(np.inner(question_embeddings['outputs'], response_embeddings['outputs']).ravel())\n",
    "\n",
    "        sample_df.loc[sample_df['query_id'] == query, 'USE_QA'] = sim\n",
    "            #sample_df.to_csv('USEQA_Full_Spelled.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_df.to_csv('USE/USEQA_Full_Spelled.tsv',sep='\\t',index=False)\n",
    "sample_df.to_csv('USE/USEQA_Full_Spelled_Stemmed.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaReQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = hub.load(\"https://tfhub.dev/google/LAReQA/mBERT_X_Y/1\")\n",
    "\n",
    "question_encoder = loaded.signatures[\"query_encoder\"]\n",
    "response_encoder = loaded.signatures[\"response_encoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('./Data/sample.csv', sep=',')\n",
    "sample_df.columns = ['query_id', 'url_id']\n",
    "\n",
    "marks_df = pd.read_csv('./Data/train.marks.tsv', sep='\\t', header=None)\n",
    "marks_df.columns = ['query_id', 'url_id', 'mark']\n",
    "marks_df = marks_df.drop(columns=['mark'])\n",
    "\n",
    "sample_df = sample_df.append(marks_df)\n",
    "\n",
    "sample_df['LaReQA'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:27<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for query in tqdm.tqdm(all_q):\n",
    "    counter += 1\n",
    "    if counter % 100:\n",
    "        sample_df.to_csv('LaReQA_Full_Spelled.tsv',sep='\\t',index=False)\n",
    "\n",
    "    docs_id = list(sample_df[sample_df['query_id'] == query]['url_id'])\n",
    "    q = queries[queries['Id'] == query]['Query'][query]\n",
    "\n",
    "    question_embeddings = question_encoder(input=tf.constant(np.asarray([q])))[\"outputs\"]\n",
    "\n",
    "    responses = titles[docs_id]\n",
    "    response_contexts = corpus[docs_id]\n",
    "    \n",
    "    response_embeddings = response_encoder(\n",
    "        input=tf.constant(responses),\n",
    "        context=tf.constant(response_contexts))[\"outputs\"]\n",
    "    \n",
    "    sim = np.matmul(question_embeddings.numpy(), np.transpose(response_embeddings.numpy()))\n",
    "    sample_df.loc[sample_df['query_id'] == query, 'LaReQA'] = sim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('LaReQA/LaReQA_Full_Spelled.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
